{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chall\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "# Image dimensions\n",
    "img_width, img_height = 150, 150 \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(p, input_shape=(32, 32, 3)):\n",
    "    # Initialising the CNN\n",
    "    model = Sequential()\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Convolution + Pooling Layer \n",
    "    # increasing the number of filters as we have pooled out features reduced features. we can afford to apply 64 filters.\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "    # Fully connection\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(p/2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "        # Compiling the CNN\n",
    "    optimizer = Adam(lr=1e-3)\n",
    "    metrics=['accuracy']\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(bs=32, epochs=10):\n",
    "    #image augmentation\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "                                       shear_range = 0.2, \n",
    "                                       zoom_range = 0.2, \n",
    "                                       horizontal_flip = True)\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    " \n",
    "    training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (img_width, img_height),\n",
    "                                                 batch_size = bs,\n",
    "                                                 class_mode = 'binary')\n",
    "                                                 \n",
    "    test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (img_width, img_height),\n",
    "                                            batch_size = bs,\n",
    "                                            class_mode = 'binary')\n",
    "                                            \n",
    "    model = create_model(p=0.6, input_shape=(img_width, img_height, 3))                                  \n",
    "    model.fit_generator(training_set,\n",
    "                         steps_per_epoch=8000/bs,\n",
    "                         epochs = epochs,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000/bs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 299s 1s/step - loss: 0.6940 - acc: 0.4995 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 187s 747ms/step - loss: 0.6936 - acc: 0.4994 - val_loss: 0.6931 - val_acc: 0.5060\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 317s 1s/step - loss: 0.6935 - acc: 0.5011 - val_loss: 0.6929 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 299s 1s/step - loss: 0.6934 - acc: 0.4960 - val_loss: 0.6925 - val_acc: 0.5520\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 186s 746ms/step - loss: 0.6917 - acc: 0.5264 - val_loss: 0.6829 - val_acc: 0.5855\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 185s 740ms/step - loss: 0.6880 - acc: 0.5584 - val_loss: 0.6767 - val_acc: 0.5630\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 180s 721ms/step - loss: 0.6723 - acc: 0.6029 - val_loss: 0.6380 - val_acc: 0.6585\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 182s 728ms/step - loss: 0.6445 - acc: 0.6434 - val_loss: 0.6403 - val_acc: 0.6370\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 183s 731ms/step - loss: 0.6240 - acc: 0.6658 - val_loss: 0.5980 - val_acc: 0.6900\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 184s 735ms/step - loss: 0.6069 - acc: 0.6716 - val_loss: 0.5755 - val_acc: 0.7090\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 182s 730ms/step - loss: 0.5996 - acc: 0.6801 - val_loss: 0.5610 - val_acc: 0.7300\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 545s 2s/step - loss: 0.5856 - acc: 0.6939 - val_loss: 0.5776 - val_acc: 0.7010\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 296s 1s/step - loss: 0.5693 - acc: 0.7150 - val_loss: 0.5629 - val_acc: 0.7275\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 181s 722ms/step - loss: 0.5511 - acc: 0.7260 - val_loss: 0.5404 - val_acc: 0.7505\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 180s 720ms/step - loss: 0.5427 - acc: 0.7276 - val_loss: 0.5244 - val_acc: 0.7630\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 181s 725ms/step - loss: 0.5246 - acc: 0.7405 - val_loss: 0.5088 - val_acc: 0.7725\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 180s 719ms/step - loss: 0.5042 - acc: 0.7598 - val_loss: 0.4869 - val_acc: 0.7805\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 181s 722ms/step - loss: 0.4920 - acc: 0.7626 - val_loss: 0.4608 - val_acc: 0.7965\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 182s 729ms/step - loss: 0.4786 - acc: 0.7804 - val_loss: 0.4756 - val_acc: 0.8000\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 180s 719ms/step - loss: 0.4746 - acc: 0.7798 - val_loss: 0.4494 - val_acc: 0.8110\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 180s 721ms/step - loss: 0.4498 - acc: 0.7925 - val_loss: 0.4479 - val_acc: 0.8065\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 180s 720ms/step - loss: 0.4507 - acc: 0.7899 - val_loss: 0.4581 - val_acc: 0.7920\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 182s 727ms/step - loss: 0.4416 - acc: 0.7985 - val_loss: 0.4940 - val_acc: 0.7815\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 180s 719ms/step - loss: 0.4331 - acc: 0.8064 - val_loss: 0.4342 - val_acc: 0.8285\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 183s 734ms/step - loss: 0.4176 - acc: 0.8131 - val_loss: 0.4094 - val_acc: 0.8350\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 181s 724ms/step - loss: 0.4043 - acc: 0.8197 - val_loss: 0.4163 - val_acc: 0.8295\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 180s 721ms/step - loss: 0.4072 - acc: 0.8193 - val_loss: 0.4483 - val_acc: 0.8295\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 181s 725ms/step - loss: 0.3927 - acc: 0.8306 - val_loss: 0.4197 - val_acc: 0.8320\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 183s 732ms/step - loss: 0.3758 - acc: 0.8350 - val_loss: 0.3910 - val_acc: 0.8455\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 182s 727ms/step - loss: 0.3732 - acc: 0.8400 - val_loss: 0.3947 - val_acc: 0.8395\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 180s 720ms/step - loss: 0.3720 - acc: 0.8371 - val_loss: 0.4004 - val_acc: 0.8440\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 181s 723ms/step - loss: 0.3552 - acc: 0.8460 - val_loss: 0.3920 - val_acc: 0.8430\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 188s 751ms/step - loss: 0.3583 - acc: 0.8429 - val_loss: 0.3747 - val_acc: 0.8410\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 662s 3s/step - loss: 0.3500 - acc: 0.8458 - val_loss: 0.3807 - val_acc: 0.8530\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 277s 1s/step - loss: 0.3465 - acc: 0.8491 - val_loss: 0.3768 - val_acc: 0.8565\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 225s 899ms/step - loss: 0.3370 - acc: 0.8539 - val_loss: 0.3610 - val_acc: 0.8550\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 195s 781ms/step - loss: 0.3394 - acc: 0.8522 - val_loss: 0.3691 - val_acc: 0.8580\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 193s 773ms/step - loss: 0.3295 - acc: 0.8550 - val_loss: 0.3982 - val_acc: 0.8435\n",
      "Epoch 39/100\n",
      " 70/250 [=======>......................] - ETA: 2:10 - loss: 0.3345 - acc: 0.8518"
     ]
    }
   ],
   "source": [
    "classifier = run_training(bs=32, epochs=100)#100 epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
